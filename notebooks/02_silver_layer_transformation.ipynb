{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99a29ad6-4588-4825-a683-8ecd5152b7ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# F1 Data Engineering Project - Silver Layer\n",
    "## Data Cleansing & Transformation\n",
    "\n",
    "This notebook transforms Bronze layer data into clean, validated Silver layer tables.\n",
    "\n",
    "**Transformations Applied:**\n",
    "- Data type conversions (dates, numbers)\n",
    "- Null value handling\n",
    "- Column renaming for business context\n",
    "- Creating derived columns\n",
    "- Data quality improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f13e32b8-38c7-4ec4-8e6b-e7b1ab9abc22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c0f3ffe-ecfd-4a7f-88b2-6a56a51f0e54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog: f1_dev\nBronze Schema: f1_dev.bronze\nSilver Schema: f1_dev.silver\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION\n",
    "\n",
    "CATALOG_NAME = \"f1_dev\"\n",
    "BRONZE_SCHEMA = \"bronze\"\n",
    "SILVER_SCHEMA = \"silver\"\n",
    "\n",
    "# Full table references\n",
    "bronze_db = f\"{CATALOG_NAME}.{BRONZE_SCHEMA}\"\n",
    "silver_db = f\"{CATALOG_NAME}.{SILVER_SCHEMA}\"\n",
    "\n",
    "print(f\"Catalog: {CATALOG_NAME}\")\n",
    "print(f\"Bronze Schema: {bronze_db}\")\n",
    "print(f\"Silver Schema: {silver_db}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d2977dc-b3ee-4acc-b23f-bb9743663626",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3791517-bbfc-4d73-9cb3-70b317c1f86f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: f1_dev.silver\n"
     ]
    }
   ],
   "source": [
    "# Set catalog context\n",
    "spark.sql(f\"USE CATALOG {CATALOG_NAME}\")\n",
    "\n",
    "# Create Silver schema if not exists\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.{SILVER_SCHEMA}\")\n",
    "spark.sql(f\"USE SCHEMA {SILVER_SCHEMA}\")\n",
    "\n",
    "print(f\"Using: {CATALOG_NAME}.{SILVER_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c53d362-f8c9-47c1-bda1-6ab3710c6875",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63aaea9e-02f4-40eb-9d1e-27940ad9a161",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, concat, lit, when, to_date, to_timestamp,\n",
    "    current_timestamp, upper, lower, trim, regexp_replace,\n",
    "    year, month, dayofmonth, split, coalesce\n",
    ")\n",
    "from pyspark.sql.types import IntegerType, DoubleType, DateType, TimestampType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "041393cd-357e-4544-985a-4dfb4253ebd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transform Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62c4bbc3-66dc-466e-96cf-1e840190e284",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] circuits: 77 records\n"
     ]
    }
   ],
   "source": [
    "# Read Bronze circuits\n",
    "circuits_bronze = spark.table(f\"{bronze_db}.circuits\")\n",
    "\n",
    "# Transform circuits - add business-friendly names\n",
    "circuits_silver = circuits_bronze \\\n",
    "    .select(\n",
    "        col(\"circuit_id\"),\n",
    "        col(\"circuit_ref\"),\n",
    "        col(\"name\").alias(\"circuit_name\"),\n",
    "        col(\"location\").alias(\"circuit_location\"),\n",
    "        col(\"country\").alias(\"circuit_country\"),\n",
    "        col(\"lat\").alias(\"latitude\"),\n",
    "        col(\"lng\").alias(\"longitude\"),\n",
    "        col(\"alt\").alias(\"altitude_meters\")\n",
    "    ) \\\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "circuits_silver.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_db}.circuits\")\n",
    "\n",
    "print(f\"[OK] circuits: {circuits_silver.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d03a4d55-2391-4d5b-a4b4-9b1390709f28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transform Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bda09e9-6d88-4b69-aeeb-97d1dca93c31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] constructors: 212 records\n"
     ]
    }
   ],
   "source": [
    "# Read Bronze constructors\n",
    "constructors_bronze = spark.table(f\"{bronze_db}.constructors\")\n",
    "\n",
    "# Transform constructors\n",
    "constructors_silver = constructors_bronze \\\n",
    "    .select(\n",
    "        col(\"constructor_id\"),\n",
    "        col(\"constructor_ref\"),\n",
    "        col(\"name\").alias(\"constructor_name\"),\n",
    "        col(\"nationality\").alias(\"constructor_nationality\")\n",
    "    ) \\\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "constructors_silver.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_db}.constructors\")\n",
    "\n",
    "print(f\"[OK] constructors: {constructors_silver.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d958370-92d6-4d2b-aadc-7d94717ce84f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transform Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b84a67f2-4d8e-4469-988e-5894702189a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] drivers: 864 records\n"
     ]
    }
   ],
   "source": [
    "# Read Bronze drivers\n",
    "drivers_bronze = spark.table(f\"{bronze_db}.drivers\")\n",
    "\n",
    "# Transform drivers - add derived columns\n",
    "drivers_silver = drivers_bronze \\\n",
    "    .select(\n",
    "        col(\"driver_id\"),\n",
    "        col(\"driver_ref\"),\n",
    "        col(\"number\").cast(IntegerType()).alias(\"driver_number\"),\n",
    "        col(\"code\").alias(\"driver_code\"),\n",
    "        col(\"forename\").alias(\"first_name\"),\n",
    "        col(\"surname\").alias(\"last_name\"),\n",
    "        concat(col(\"forename\"), lit(\" \"), col(\"surname\")).alias(\"full_name\"),\n",
    "        to_date(col(\"dob\"), \"yyyy-MM-dd\").alias(\"date_of_birth\"),\n",
    "        col(\"nationality\").alias(\"driver_nationality\")\n",
    "    ) \\\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "drivers_silver.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_db}.drivers\")\n",
    "\n",
    "print(f\"[OK] drivers: {drivers_silver.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f85c8729-2254-4dd8-8be9-576545f0e887",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transform Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32f929e3-f969-440d-b956-94acd6d3435e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] races: 1,149 records\n"
     ]
    }
   ],
   "source": [
    "# Read Bronze races\n",
    "races_bronze = spark.table(f\"{bronze_db}.races\")\n",
    "\n",
    "# Transform races\n",
    "races_silver = races_bronze \\\n",
    "    .select(\n",
    "        col(\"race_id\"),\n",
    "        col(\"year\").alias(\"race_year\"),\n",
    "        col(\"round\").alias(\"race_round\"),\n",
    "        col(\"circuit_id\"),\n",
    "        col(\"name\").alias(\"race_name\"),\n",
    "        to_date(col(\"date\"), \"yyyy-MM-dd\").alias(\"race_date\"),\n",
    "        col(\"time\").alias(\"race_time\"),\n",
    "        to_date(col(\"quali_date\"), \"yyyy-MM-dd\").alias(\"qualifying_date\"),\n",
    "        col(\"quali_time\").alias(\"qualifying_time\"),\n",
    "        to_date(col(\"sprint_date\"), \"yyyy-MM-dd\").alias(\"sprint_date\"),\n",
    "        col(\"sprint_time\").alias(\"sprint_time\")\n",
    "    ) \\\n",
    "    .withColumn(\"race_datetime\", \n",
    "                when(col(\"race_time\").isNotNull(), \n",
    "                     to_timestamp(concat(col(\"race_date\"), lit(\" \"), col(\"race_time\"))))\n",
    "                .otherwise(None)) \\\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "races_silver.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_db}.races\")\n",
    "\n",
    "print(f\"[OK] races: {races_silver.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ae2f106-768b-426b-bbbb-c1dc02cb33f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transform Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5dba835-3e29-467e-9e6b-f0548b62ff94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] results: 27,238 records\n"
     ]
    }
   ],
   "source": [
    "# Read Bronze results\n",
    "results_bronze = spark.table(f\"{bronze_db}.results\")\n",
    "\n",
    "# Transform results - add derived columns for analytics\n",
    "results_silver = results_bronze \\\n",
    "    .select(\n",
    "        col(\"result_id\"),\n",
    "        col(\"race_id\"),\n",
    "        col(\"driver_id\"),\n",
    "        col(\"constructor_id\"),\n",
    "        col(\"number\").cast(IntegerType()).alias(\"driver_number\"),\n",
    "        col(\"grid\").alias(\"grid_position\"),\n",
    "        col(\"position\").cast(IntegerType()).alias(\"finish_position\"),\n",
    "        col(\"position_text\"),\n",
    "        col(\"position_order\"),\n",
    "        col(\"points\").alias(\"points_earned\"),\n",
    "        col(\"laps\").alias(\"laps_completed\"),\n",
    "        col(\"time\").alias(\"finish_time\"),\n",
    "        col(\"milliseconds\").cast(IntegerType()).alias(\"time_milliseconds\"),\n",
    "        col(\"fastest_lap\").cast(IntegerType()).alias(\"fastest_lap_number\"),\n",
    "        col(\"rank\").cast(IntegerType()).alias(\"fastest_lap_rank\"),\n",
    "        col(\"fastest_lap_time\"),\n",
    "        col(\"fastest_lap_speed\").cast(DoubleType()).alias(\"fastest_lap_speed_kph\"),\n",
    "        col(\"status_id\")\n",
    "    ) \\\n",
    "    .withColumn(\"is_winner\", when(col(\"finish_position\") == 1, True).otherwise(False)) \\\n",
    "    .withColumn(\"is_podium\", when(col(\"finish_position\") <= 3, True).otherwise(False)) \\\n",
    "    .withColumn(\"is_points_finish\", when(col(\"points_earned\") > 0, True).otherwise(False)) \\\n",
    "    .withColumn(\"positions_gained\", col(\"grid_position\") - col(\"finish_position\")) \\\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "results_silver.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_db}.results\")\n",
    "\n",
    "print(f\"[OK] results: {results_silver.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "547dd066-0995-4d59-b740-4170efb6a9c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transform Qualifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b49f4a3-53e5-473f-9deb-e192a3d86ccf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] qualifying: 10,973 records\n"
     ]
    }
   ],
   "source": [
    "# Read Bronze qualifying\n",
    "qualifying_bronze = spark.table(f\"{bronze_db}.qualifying\")\n",
    "\n",
    "# Transform qualifying\n",
    "qualifying_silver = qualifying_bronze \\\n",
    "    .select(\n",
    "        col(\"qualify_id\"),\n",
    "        col(\"race_id\"),\n",
    "        col(\"driver_id\"),\n",
    "        col(\"constructor_id\"),\n",
    "        col(\"number\").alias(\"driver_number\"),\n",
    "        col(\"position\").alias(\"qualifying_position\"),\n",
    "        col(\"q1\").alias(\"q1_time\"),\n",
    "        col(\"q2\").alias(\"q2_time\"),\n",
    "        col(\"q3\").alias(\"q3_time\")\n",
    "    ) \\\n",
    "    .withColumn(\"reached_q2\", when(col(\"q2_time\").isNotNull(), True).otherwise(False)) \\\n",
    "    .withColumn(\"reached_q3\", when(col(\"q3_time\").isNotNull(), True).otherwise(False)) \\\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "qualifying_silver.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_db}.qualifying\")\n",
    "\n",
    "print(f\"[OK] qualifying: {qualifying_silver.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "692c19da-8f61-4b8c-9d8e-265b5db79540",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transform Lap Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "505eb3bb-76a3-4706-aa77-2c83d659b523",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] lap_times: 615,738 records\n"
     ]
    }
   ],
   "source": [
    "# Read Bronze lap times\n",
    "lap_times_bronze = spark.table(f\"{bronze_db}.lap_times\")\n",
    "\n",
    "# Transform lap times\n",
    "lap_times_silver = lap_times_bronze \\\n",
    "    .select(\n",
    "        col(\"race_id\"),\n",
    "        col(\"driver_id\"),\n",
    "        col(\"lap\").alias(\"lap_number\"),\n",
    "        col(\"position\"),\n",
    "        col(\"time\").alias(\"lap_time\"),\n",
    "        col(\"milliseconds\").alias(\"lap_time_ms\")\n",
    "    ) \\\n",
    "    .withColumn(\"lap_time_seconds\", col(\"lap_time_ms\") / 1000.0) \\\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "lap_times_silver.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_db}.lap_times\")\n",
    "\n",
    "print(f\"[OK] lap_times: {lap_times_silver.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd89a7c1-db70-441f-83fc-f18705fb1796",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transform Pit Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a75d3975-9edf-463c-a4f6-963df66cee49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] pit_stops: 12,192 records\n"
     ]
    }
   ],
   "source": [
    "# Read Bronze pit stops\n",
    "pit_stops_bronze = spark.table(f\"{bronze_db}.pit_stops\")\n",
    "\n",
    "# Transform pit stops\n",
    "pit_stops_silver = pit_stops_bronze \\\n",
    "    .select(\n",
    "        col(\"race_id\"),\n",
    "        col(\"driver_id\"),\n",
    "        col(\"stop\").alias(\"stop_number\"),\n",
    "        col(\"lap\").alias(\"lap_number\"),\n",
    "        col(\"time\").alias(\"time_of_day\"),\n",
    "        col(\"duration\").alias(\"pit_duration\"),\n",
    "        col(\"milliseconds\").alias(\"pit_duration_ms\")\n",
    "    ) \\\n",
    "    .withColumn(\"pit_duration_seconds\", col(\"pit_duration_ms\") / 1000.0) \\\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "pit_stops_silver.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_db}.pit_stops\")\n",
    "\n",
    "print(f\"[OK] pit_stops: {pit_stops_silver.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edad51fb-a0f3-4125-b43d-33ffd50d4df4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transform Driver Standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce2d2f9f-5645-4ef1-b0c5-34ec998240e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] driver_standings: 35,361 records\n"
     ]
    }
   ],
   "source": [
    "# Read Bronze driver standings\n",
    "driver_standings_bronze = spark.table(f\"{bronze_db}.driver_standings\")\n",
    "\n",
    "# Transform driver standings\n",
    "driver_standings_silver = driver_standings_bronze \\\n",
    "    .select(\n",
    "        col(\"driver_standings_id\"),\n",
    "        col(\"race_id\"),\n",
    "        col(\"driver_id\"),\n",
    "        col(\"points\").alias(\"championship_points\"),\n",
    "        col(\"position\").alias(\"championship_position\"),\n",
    "        col(\"position_text\"),\n",
    "        col(\"wins\").alias(\"total_wins\")\n",
    "    ) \\\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "driver_standings_silver.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_db}.driver_standings\")\n",
    "\n",
    "print(f\"[OK] driver_standings: {driver_standings_silver.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbd04877-e405-4e61-9b65-6136a6de3e8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transform Constructor Standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "965c9bd7-bf2c-434d-882c-29a5a234bac3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] constructor_standings: 13,631 records\n"
     ]
    }
   ],
   "source": [
    "# Read Bronze constructor standings\n",
    "constructor_standings_bronze = spark.table(f\"{bronze_db}.constructor_standings\")\n",
    "\n",
    "# Transform constructor standings\n",
    "constructor_standings_silver = constructor_standings_bronze \\\n",
    "    .select(\n",
    "        col(\"constructor_standings_id\"),\n",
    "        col(\"race_id\"),\n",
    "        col(\"constructor_id\"),\n",
    "        col(\"points\").alias(\"championship_points\"),\n",
    "        col(\"position\").alias(\"championship_position\"),\n",
    "        col(\"position_text\"),\n",
    "        col(\"wins\").alias(\"total_wins\")\n",
    "    ) \\\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "constructor_standings_silver.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_db}.constructor_standings\")\n",
    "\n",
    "print(f\"[OK] constructor_standings: {constructor_standings_silver.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5df8e7b1-963b-4384-bcbd-6001bac0248e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transform Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "661654b1-bb9e-49f3-b0b3-b5fd9a269083",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] status: 139 records\n"
     ]
    }
   ],
   "source": [
    "# Read Bronze status\n",
    "status_bronze = spark.table(f\"{bronze_db}.status\")\n",
    "\n",
    "# Transform status - add status categories\n",
    "status_silver = status_bronze \\\n",
    "    .select(\n",
    "        col(\"status_id\"),\n",
    "        col(\"status\").alias(\"status_description\")\n",
    "    ) \\\n",
    "    .withColumn(\"status_category\",\n",
    "                when(col(\"status_description\") == \"Finished\", \"Finished\")\n",
    "                .when(col(\"status_description\").like(\"%Lap%\"), \"Lapped\")\n",
    "                .when(col(\"status_description\").isin(\"Disqualified\", \"Excluded\", \"Not classified\"), \"Disqualified/NC\")\n",
    "                .when(col(\"status_description\").isin(\"Accident\", \"Collision\", \"Collision damage\", \"Spun off\"), \"Accident\")\n",
    "                .when(col(\"status_description\").like(\"%Engine%\") | \n",
    "                      col(\"status_description\").like(\"%Gearbox%\") |\n",
    "                      col(\"status_description\").like(\"%Transmission%\") |\n",
    "                      col(\"status_description\").like(\"%Hydraulic%\") |\n",
    "                      col(\"status_description\").like(\"%Electrical%\") |\n",
    "                      col(\"status_description\").like(\"%Brake%\") |\n",
    "                      col(\"status_description\").like(\"%Suspension%\"), \"Mechanical\")\n",
    "                .when(col(\"status_description\") == \"Retired\", \"Retired\")\n",
    "                .otherwise(\"Other DNF\")) \\\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "status_silver.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_db}.status\")\n",
    "\n",
    "print(f\"[OK] status: {status_silver.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a824fe46-80b8-4e3e-a00e-5da8b0b3d757",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transform Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e032b1f3-5041-4d1d-9e46-7c810a8359c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] seasons: 76 records\n"
     ]
    }
   ],
   "source": [
    "# Read Bronze seasons\n",
    "seasons_bronze = spark.table(f\"{bronze_db}.seasons\")\n",
    "\n",
    "# Transform seasons\n",
    "seasons_silver = seasons_bronze \\\n",
    "    .select(\n",
    "        col(\"year\").alias(\"season_year\"),\n",
    "        col(\"url\").alias(\"season_url\")\n",
    "    ) \\\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    "\n",
    "# Write to Silver\n",
    "seasons_silver.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_db}.seasons\")\n",
    "\n",
    "print(f\"[OK] seasons: {seasons_silver.count():,} records\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_layer_transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}